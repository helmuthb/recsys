{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fbeaa343b8ffec272d9fc3a4be1b6418",
     "grade": false,
     "grade_id": "cell-97cccb99056a50da",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "Welcome to the second assignment! Here you will implement Matrix Factorization. We will use part of the MovieLens 20M dataset.\n",
    "\n",
    "You will write and execute your code in Python using this Jupyter Notebook.\n",
    "\n",
    "**PREREQUISITE:** Download the MovieLens 20M dataset from <https://grouplens.org/datasets/movielens/20m/>. Extract the contents and look up `ratings.csv`, which is what we'll be working with.\n",
    "\n",
    "**TASK:** Your job is to *fill in the missing code* only. The place to enter your code is clearly marked with comments.\n",
    "\n",
    "**SUBMISSION:** You will submit this Notebook via TUWEL.\n",
    "\n",
    "**GRADING:** We will test whether your code produces the expected output. Therefore hidden tests will compare results of the standard solution with yours (based on the whole dataset - multiple, randomly selected inputs - accuracy of the sulution must be within two decimal places).\n",
    "\n",
    "Note that there is a variable `DEBUG` set to `True` for debugging/testing purposes. **For this assignment all tests will be based on the truncated dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8be4e4edda9cefb8590f06623ba362bc",
     "grade": false,
     "grade_id": "cell-b005278d6bf3a879",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Preparation\n",
    "\n",
    "Import some basic python modules and set some print formatting options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "beba8e9d97eb18fb636553d5e99e107b",
     "grade": false,
     "grade_id": "cell-86010308b212db8e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "from scipy.sparse.linalg import norm\n",
    "import sklearn.preprocessing as pp\n",
    "import sys\n",
    "import math\n",
    "\n",
    "np.set_printoptions(threshold=500, precision=4)\n",
    "pd.options.display.max_seq_items = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6533b19027ccef3e341fa32a5417f70b",
     "grade": false,
     "grade_id": "cell-9e840921bd25e4c5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Read the data\n",
    "\n",
    "We will work with a *truncated* version of the MovieLens 20M dataset, containing up to 10000 users and 1000 movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "data_location = '../../data/ratings.csv' ## SOME LOCATION OF YOUR CHOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a4921305e54b37aeed2b4ee5e99f372",
     "grade": true,
     "grade_id": "read_files",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9e6eeaeaac65f3c320bf5f83a014c974",
     "grade": false,
     "grade_id": "cell-93e9b706447fca97",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ratings_raw = pd.read_csv(data_location)\n",
    "if DEBUG:\n",
    "    ratings_raw = ratings_raw[ (ratings_raw['userId'] < 10000) & (ratings_raw['movieId'] < 1000) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cff6ca8150d7ced37507531f7bd57703",
     "grade": false,
     "grade_id": "cell-b6f5b803d77ae57c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's see how the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "453204075976c17a2dba05c936f177bf",
     "grade": false,
     "grade_id": "cell-07c039b90854a742",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ratings_raw.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c323569c517488c51e9d38845e5b3348",
     "grade": false,
     "grade_id": "cell-55bf2cf5d9b74332",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Preprocess the data\n",
    "\n",
    "We make sure that movies and users have consecutive indexes starting from 0. We also drop the timestamp column.\n",
    "\n",
    "The resulting \"cleaned\" data are stored in `ratings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a7d55d88c178451ffde659825131811c",
     "grade": false,
     "grade_id": "cell-3d2a2a672c47daad",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9924 users, 968 items and 394638 ratings.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating\n",
       "0     0     1     3.5\n",
       "1     0    28     3.5\n",
       "2     0    31     3.5\n",
       "3     0    46     3.5\n",
       "4     0    49     3.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movieIds = ratings_raw.movieId.unique()\n",
    "movieIds.sort()\n",
    "userIds = ratings_raw.userId.unique()\n",
    "userIds.sort()\n",
    "\n",
    "m = userIds.size\n",
    "n = movieIds.size\n",
    "numRatings = len(ratings_raw)\n",
    "\n",
    "print (\"There are\", m, \"users,\", n, \"items and\", numRatings, \"ratings.\")\n",
    "\n",
    "## movies and users should have consecutive indexes starting from 0\n",
    "movieId_to_movieIDX = dict(zip(movieIds, range(0, movieIds.size)))\n",
    "movieIDX_to_movieId = dict(zip(range(0, movieIds.size), movieIds))\n",
    "\n",
    "userId_to_userIDX = dict(zip(userIds, range(0, userIds.size )))\n",
    "userIDX_to_userId = dict(zip(range(0, userIds.size), userIds))\n",
    "\n",
    "## drop timestamps\n",
    "ratings = pd.concat([ratings_raw['userId'].map(userId_to_userIDX), ratings_raw['movieId'].map(movieId_to_movieIDX), ratings_raw['rating']], axis=1)\n",
    "ratings.columns = ['user', 'item', 'rating']\n",
    "\n",
    "display(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc0c12ef8282c0194747cb1b983fdeb7",
     "grade": false,
     "grade_id": "cell-f4387b842237cc9c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Create the Ratings Matrix\n",
    "\n",
    "We will convert the `ratings` `DataFrame` into a **Ratings Matrix**. Because it is very sparse, we will use the `scipy.sparse` module to efficiently store and access it.\n",
    "\n",
    "Specifically, we will create the ratings matrix `R` stored in the Compressed Sparse Row format (`csr_matrix`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8bf3f040b2d362080cd554d7aec681d7",
     "grade": false,
     "grade_id": "cell-911fe1641deb6475",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "R = sp.csr_matrix((ratings.rating, (ratings.user, ratings.item)))\n",
    "\n",
    "m = R.shape[0]\n",
    "n = R.shape[1]\n",
    "n_ratings = R.count_nonzero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3a3b6c68656996b30c5403c8109dd80f",
     "grade": false,
     "grade_id": "cell-e866ad97ac13859e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## The fun starts here!\n",
    "\n",
    "Import additional modules to simplify some operations, and define some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf6b06bde330a5c50aee4d672d5a38dd",
     "grade": false,
     "grade_id": "cell-6ed1a94834d4aa91",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_one_hot(targets):\n",
    "    lb = pp.LabelBinarizer(sparse_output=True)\n",
    "    lb.fit(targets.reshape(-1))\n",
    "    return lb.transform(targets)\n",
    "\n",
    "\n",
    "def to_Xy_format(R):\n",
    "    n_users = R.shape[0]\n",
    "    n_items = R.shape[1]\n",
    "\n",
    "    users, items = R.nonzero()\n",
    "    n_ratings = users.size\n",
    "\n",
    "    Xu = get_one_hot(users)\n",
    "    Xi = get_one_hot(items)\n",
    "\n",
    "    R = sp.csr_matrix(R)\n",
    "    y = R.data\n",
    "    X = sp.hstack([Xu, Xi])\n",
    "\n",
    "    return X, y, n_users, n_items\n",
    "\n",
    "\n",
    "def to_R_format(X, y, n_users, n_items):\n",
    "    Xu = X.tocsc()[:, :n_users]\n",
    "    Xi = X.tocsc()[:, n_users:]\n",
    "\n",
    "    Xu = Xu.tocsr()\n",
    "    Xi = Xi.tocsr()\n",
    "\n",
    "    R_rec = sp.coo_matrix( (y, (Xu.indices, Xi.indices)), shape=(n_users, n_items) )\n",
    "\n",
    "    return R_rec.tocsr()\n",
    "\n",
    "\n",
    "def to_UI_arrays(X, n_users, n_items):\n",
    "    Xu = X.tocsc()[:, :n_users]\n",
    "    Xi = X.tocsc()[:, n_users:]\n",
    "\n",
    "    U = Xu.argmax(axis=1).A1\n",
    "    I = Xi.argmax(axis=1).A1\n",
    "    \n",
    "    return U, I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2af64caaf686b7e9bb4d362ef69483ff",
     "grade": false,
     "grade_id": "cell-3061121fce579cbf",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "While the ratings matrix `R` is very intuitive, sometimes it is more convenient to have a view of one rating (training example) at a time in terms of the `X` and `y` arrays.\n",
    "\n",
    "The `X` array has $m+n$ columns, where the first $m$ one-hot encode the user, and the other $n$ the item. So a row of `X` has exactly two `1`s and all other entries are zero. Array `X` has as many rows as the number of ratings. So, the shape of `X` is `(n_ratings, n_users+n_items)`. (Actually `X` is stored as a sparse matrix, so the corresponding dense matrix has that shape.)\n",
    "\n",
    "The `y` array has a single column, and each row contains the rating for user, item pair indicated by the corresponding row in the `X` array. So, the shape of `y` is `(n_ratings,)`.\n",
    "\n",
    "The above functions convert between the two formats. Note that to convert from the `Xy` format you need to know the number of users and items, `n_users`, `n_items` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0d08890332d1839d5c917be95babf002",
     "grade": false,
     "grade_id": "cell-100f9c5cc7f89af2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X, y, n_users, n_items = to_Xy_format(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "144afc93119d8556bf14d303f6d99f25",
     "grade": false,
     "grade_id": "cell-472502a1c6b22b6e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Build the MatrixFactorization class\n",
    "\n",
    "In the following, we will build functionality into a `MatrixFactorization` class, which inherits from the [scikit-learn](http://scikit-learn.org) classes `BaseEstimator` and `RegressorMixin`. The reason we follow the scikit-learn API is that we may want to use some of the functionality offered, such as hyperparameter tuning; but not in this assignment. If you're interested, refer to <http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator> for more on the scikit-learn API.\n",
    "\n",
    "The model uses the following hyperparameters:\n",
    "\n",
    "- `k` is the number of factors\n",
    "- `eta` is the learning rate $\\eta$ of SGD\n",
    "- `lam` is the regularization strength $\\lambda$\n",
    "- `n_epochs` is the number of epochs to run SGD\n",
    "- `s_batch` is the size of the batch in the mini-batch SGD (bonus point)\n",
    "- `w_average` indicates if the overall average rating is used in the baseline prediction\n",
    "- `w_biases` indicates if user and item biases are used in the baseline prediction\n",
    "- `rnd_mean` and `rnd_std` are the mean and std. deviation of the Normal distribution used for initializing the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc6b2ad3a637d85384e437498e313981",
     "grade": false,
     "grade_id": "cell-66042ba2379a0633",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "class MatrixFactorization(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, k = 5, eta = 0.002, lam = 0., n_epochs = 5, s_batch = 1, w_average = True, w_biases = True, rnd_mean = 0, rnd_std = 0.1):\n",
    "        self.k = k\n",
    "        self.eta = eta\n",
    "        self.lam = lam\n",
    "        self.n_epochs = n_epochs\n",
    "        self.s_batch = s_batch\n",
    "        self.w_average = w_average\n",
    "        self.w_biases = w_biases\n",
    "        self.rnd_mean = rnd_mean\n",
    "        self.rnd_std = rnd_std\n",
    "\n",
    "        \n",
    "class LossObserver():\n",
    "    def __init__(self, loss=sys.maxsize):\n",
    "        self.loss = loss\n",
    "        \n",
    "        \n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6749f127998f1691a33bb368174e3a4e",
     "grade": false,
     "grade_id": "cell-4c22b2467e69a414",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Prepare for training --- TO EDIT\n",
    "\n",
    "The model you will build should make predictions as:\n",
    "\n",
    "$$ \\hat{r}_{ui} = \\mu + b_u + b_i + p_u^\\intercal q_i $$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\mu$ is the overall average rating and should be stored in `self.mu_`;\n",
    "- $b_u$ is a user bias; all user biases should be stored in array `self.bu_` of shape `(n_users, )`;\n",
    "- $b_i$ is a item bias; all item biases should be stored in array `self.bi_` of shape `(n_items, )`;\n",
    "- $p_u$ is the feature vector of a user; all user feature vectors should be stored in array `self.P_` of shape `(n_users, k)`;\n",
    "- $q_i$ is the feature vector of an item; all item feature vectors should be stored in array `self.Q_` of shape `(n_items, k)`.\n",
    "\n",
    "Note that variables depending on the input data typically have a trailing underscore, as in `self.mu_`, and are computed in the `fit` method.\n",
    "In contrast, variables that do not depend on the input data but on the model, such as hyperparameters, do not have a trailing underscore and are set in the `__init__` method.\n",
    "\n",
    "** TASK: ** The `fit_init` method below should:\n",
    "1. compute the overall average rating `self.mu_`, and\n",
    "2. initialize the four arrays (`self.bu_`, `self.bi_`, `self.P_`, `self.Q_`) with values selected at random from a Normal distribution with mean `self.rnd_mean` and standard deviation `self.rnd_std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "84538788fb5b65ffc2bce86eb0b3d70e",
     "grade": false,
     "grade_id": "fit_init",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_init(self, X, y, n_users, n_items):\n",
    "    X, y = check_X_y(X, y, accept_sparse=True)\n",
    "\n",
    "    self.n_users_ = n_users\n",
    "    self.n_items_ = n_items\n",
    "    self.n_ratings_ = X.shape[0]\n",
    "\n",
    "    self.X_ = X\n",
    "    self.y_ = y\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    self.mu_ = np.mean(y)\n",
    "    self.P_ = np.random.normal(self.rnd_mean, self.rnd_std, n_users * self.k)\n",
    "    self.P_.shape = (n_users, self.k)\n",
    "    self.Q_ = np.random.normal(self.rnd_mean, self.rnd_std, n_items * self.k)\n",
    "    self.Q_.shape = (n_items, self.k)\n",
    "    self.bu_ = np.random.normal(self.rnd_mean, self.rnd_std, n_users)\n",
    "    self.bi_ = np.random.normal(self.rnd_mean, self.rnd_std, n_items)\n",
    "        \n",
    "    ## random shuffle the training data\n",
    "    self.X_, self.y_ = shuffle(self.X_, self.y_)\n",
    "    \n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "348d0b6cca989c43e8789c76e5333e5b",
     "grade": false,
     "grade_id": "cell-86bd334d59cd4766",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Include the above function in the `MatrixFactorization` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "10824b90eb384c369286fc20d822fdc9",
     "grade": false,
     "grade_id": "cell-40f887f2aa2d185e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "MatrixFactorization.fit_init = fit_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2731534e10714f3a9d196756f55b315d",
     "grade": false,
     "grade_id": "cell-5a1e607178d41c18",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf.mu_ = 3.538466898778121\n",
      "\n",
      "parameters before training:\n",
      "mf.P_ = [[ 0.1624 -0.0612 -0.0528 -0.1073  0.0865]\n",
      " [-0.2302  0.1745 -0.0761  0.0319 -0.0249]\n",
      " [ 0.1462 -0.206  -0.0322 -0.0384  0.1134]\n",
      " ...\n",
      " [ 0.0736 -0.0751 -0.0063 -0.02    0.008 ]\n",
      " [-0.0331  0.1172 -0.0343 -0.0628 -0.0425]\n",
      " [ 0.0315  0.0229  0.0233 -0.0419 -0.0543]]\n",
      "mf.Q_ = [[ 0.1182 -0.1105  0.0121  0.0044  0.0354]\n",
      " [ 0.0142  0.1286  0.024   0.1653 -0.0519]\n",
      " [ 0.0515 -0.0941 -0.1337  0.0395 -0.0346]\n",
      " ...\n",
      " [ 0.0525 -0.0582 -0.1166  0.0404 -0.036 ]\n",
      " [ 0.0518  0.0134 -0.1122  0.0342  0.006 ]\n",
      " [-0.0915 -0.025   0.1451 -0.1112 -0.1196]]\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    mf = MatrixFactorization()\n",
    "\n",
    "    mf.fit_init(X, y, n_users, n_items)\n",
    "\n",
    "    print(\"mf.mu_ =\", mf.mu_)\n",
    "\n",
    "    print()\n",
    "    print(\"parameters before training:\")\n",
    "    print(\"mf.P_ =\", mf.P_)\n",
    "    print(\"mf.Q_ =\", mf.Q_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f7b02b427064e7f329113f75fbab457e",
     "grade": false,
     "grade_id": "cell-e53582269a9d1a32",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**DEBUG:** The previous cell should output:\n",
    "```\n",
    "mf.mu_ = 3.538466898778121\n",
    "\n",
    "parameters before training:\n",
    "mf.P_ = [[ 0.1624 -0.0612 -0.0528 -0.1073  0.0865]\n",
    " [-0.2302  0.1745 -0.0761  0.0319 -0.0249]\n",
    " [ 0.1462 -0.206  -0.0322 -0.0384  0.1134]\n",
    " ...\n",
    " [ 0.0736 -0.0751 -0.0063 -0.02    0.008 ]\n",
    " [-0.0331  0.1172 -0.0343 -0.0628 -0.0425]\n",
    " [ 0.0315  0.0229  0.0233 -0.0419 -0.0543]]\n",
    "mf.Q_ = [[ 0.1182 -0.1105  0.0121  0.0044  0.0354]\n",
    " [ 0.0142  0.1286  0.024   0.1653 -0.0519]\n",
    " [ 0.0515 -0.0941 -0.1337  0.0395 -0.0346]\n",
    " ...\n",
    " [ 0.0525 -0.0582 -0.1166  0.0404 -0.036 ]\n",
    " [ 0.0518  0.0134 -0.1122  0.0342  0.006 ]\n",
    " [-0.0915 -0.025   0.1451 -0.1112 -0.1196]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e3eadd646705bea5b265ff57e55429e7",
     "grade": true,
     "grade_id": "fit_init-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "355a84d0554c7248193cd9f04e3eb704",
     "grade": false,
     "grade_id": "cell-51e7cc7fad701380",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Implement Stochastic Gradient Descent --- TO EDIT\n",
    "\n",
    "The full prediction model is:\n",
    "$$ \\hat{r}_{ui} = \\mu + b_u + b_i + p_u^\\intercal q_i .$$\n",
    "\n",
    "** TASK: ** The `fit_sgd` method should do the following for each rating $r_{ui}$:\n",
    "\n",
    "1. Compute the prediction and store it in variable `prediction`.\n",
    "    - If `self.w_average` and `self.w_biases` are both `True` then `prediction` should be computed as $\\mu + b_u + b_i + p_u^\\intercal q_i$.\n",
    "    - If one of the flags `self.w_average`, `self.w_biases` are `False`, then the baseline prediction should be appropriately changed. For example, if they are both false then `prediction` should simply be computed as $p_u^\\intercal q_i$.\n",
    "\n",
    "2. Compute the prediction error $e_{ui}$ and store it in variable `err`.\n",
    "\n",
    "3. Perform a step of SGD. That is implement the update rules:\n",
    "\n",
    "$$p_u \\gets p_u + \\eta \\cdot (e_{ui} \\cdot q_i - \\lambda \\cdot p_u)$$\n",
    "$$q_i \\gets q_i + \\eta \\cdot (e_{ui} \\cdot p_u - \\lambda \\cdot q_i)$$\n",
    "$$b_u \\gets b_u + \\eta \\cdot (e_{ui} - \\lambda \\cdot b_u)$$\n",
    "$$b_i \\gets b_i + \\eta \\cdot (e_{ui} - \\lambda \\cdot b_i)$$\n",
    "\n",
    "Make sure you only update the biases if `self.w_biases` is `True`.\n",
    "\n",
    "The `fit` method is just a wrapper for `fit_sgd` and `fit_mgd` (the last is bonus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "dd99f96b7ff4232be15a2a453f871695",
     "grade": false,
     "grade_id": "fit_sgd_mgd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "obs = LossObserver()\n",
    "\n",
    "def fit_sgd(self): ## stochastic gradient descent\n",
    "    \n",
    "    U, I = to_UI_arrays(self.X_, self.n_users_, self.n_items_)\n",
    "    \n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"start of training\")\n",
    "\n",
    "    for epoch in range(self.n_epochs):\n",
    "\n",
    "        epoch_loss = 0.\n",
    "\n",
    "        for index in range(self.y_.shape[0]):\n",
    "            u = U[index]\n",
    "            i = I[index]\n",
    "            r_ui = self.y_[index]\n",
    "            \n",
    "            # YOUR CODE HERE\n",
    "            prediction = self.P_[u].T.dot(self.Q_[i])\n",
    "            if self.w_average:\n",
    "                prediction += self.mu_\n",
    "            if self.w_biases:\n",
    "                prediction += self.bu_[u] + self.bi_[i]\n",
    "            \n",
    "            err = r_ui - prediction\n",
    "            self.P_[u] += self.eta * (err * self.Q_[i] - self.lam * self.P_[u])\n",
    "            self.Q_[i] += self.eta * (err * self.P_[u] - self.lam * self.Q_[i])\n",
    "            if self.w_biases:\n",
    "                self.bu_[u] += self.eta * (err - self.lam * self.bu_[u])\n",
    "                self.bi_[i] += self.eta * (err - self.lam * self.bi_[i])\n",
    "            \n",
    "            epoch_loss += err * err\n",
    "\n",
    "        ## epoch is done\n",
    "        epoch_loss /= self.n_ratings_\n",
    "        obs.loss = epoch_loss\n",
    "        if VERBOSE:\n",
    "            print(\"epoch\", epoch, \"loss\", epoch_loss)\n",
    "\n",
    "    return self\n",
    "\n",
    "\n",
    "def fit(self, X, y, n_users, n_items):\n",
    "    self.fit_init(X, y, n_users, n_items)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(self.get_params())\n",
    "\n",
    "    if self.s_batch == 1: ## stochastic gradient descent\n",
    "        self.fit_sgd()\n",
    "    else: ## mini-batch stochastic gradient descent -- BONUS point\n",
    "        self.fit_mgd()\n",
    "\n",
    "    return self\n",
    "\n",
    "\n",
    "# For more info about fit_mgt see Section BONUS Point\n",
    "def fit_mgd(self): ## minibatch gradient descent, vectorized        \n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"start training\")\n",
    "\n",
    "    print(self.n_users_, self.n_items_)\n",
    "    print(\"X_\", self.X_.shape)\n",
    "\n",
    "    print(\"self.P_\", self.P_.shape)\n",
    "    \n",
    "    for epoch in range(self.n_epochs):\n",
    "\n",
    "        epoch_loss = 0.\n",
    "\n",
    "        for XB, yB in iterate_minibatches(self.X_, self.y_, self.s_batch):\n",
    "            XB_U = XB[:,0:self.n_users_]\n",
    "            XB_I = XB[:,self.n_users_:]\n",
    "            PB = self.P_.dot(XB_U).T\n",
    "            QB = self.Q_.dot(XB_I).T\n",
    "            # prediction = PB.T.dot(QB)\n",
    "            prediction = QB.T.dot(PB)\n",
    "            print(\"prediction\", prediction.shape)\n",
    "            if self.w_average:\n",
    "                prediction += self.mu_\n",
    "            if self.w_biases:\n",
    "                prediction += self.bu_.dot(XB) + self.bi_.dot(yB)\n",
    "            err = self.y_.dot(yB) - prediction\n",
    "            print(\"err\", err.shape)\n",
    "            self.P_ += self.eta * (err.T.dot(QB) - self.lam * PB)\n",
    "            self.Q_ += self.eta * (err.T.dot(PB) - self.lam * QB)\n",
    "            if self.w_biases:\n",
    "               self.bu_ += self.eta * (err - self.lam * self.bu_.dot(XB))\n",
    "               self.bi_ += self.eta * (err - self.lam * self.bi_.dot(yB))\n",
    "            print(\"epoch_loss\", epoch_loss)\n",
    "            epoch_loss += err.T.dot(err)\n",
    "\n",
    "        epoch_loss /= self.n_ratings_\n",
    "        obs.loss = epoch_loss\n",
    "        \n",
    "        if VERBOSE:\n",
    "            print(\"epoch\", epoch, \"loss\", epoch_loss)\n",
    "\n",
    "    return self\n",
    "\n",
    "MatrixFactorization.fit_mgd = fit_mgd\n",
    "\n",
    "# helper for fit_mgt (BONUS POINT)\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f1e89c3b30dd1cff235b06943b090e6",
     "grade": false,
     "grade_id": "cell-76f2b1a3a1d8c800",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Include the above functions in the `MatrixFactorization` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9bd539256d08929ccc56595aaa2d3d44",
     "grade": false,
     "grade_id": "cell-4ef753d343963cb5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "MatrixFactorization.fit_sgd = fit_sgd\n",
    "MatrixFactorization.fit = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d87fd9480dae40abb6c4137b83e320e4",
     "grade": false,
     "grade_id": "cell-971c4a48c783dc13",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if DEBUG:   \n",
    "    print(\"model without baseline\")\n",
    "    mf.w_average = False\n",
    "    mf.w_biases = False\n",
    "    mf.fit(X, y, n_users, n_items)\n",
    "\n",
    "    print()\n",
    "    print(\"after training:\")\n",
    "    print(\"mf.P_ =\", mf.P_)\n",
    "    print(\"mf.Q_ =\", mf.Q_)\n",
    "    \n",
    "    print()\n",
    "    print(\"model with baseline\")\n",
    "    mf.w_average = True\n",
    "    mf.w_biases = True\n",
    "    mf.fit(X, y, n_users, n_items)\n",
    "\n",
    "    print()\n",
    "    print(\"after training:\")\n",
    "    print(\"mf.P_ =\", mf.P_)\n",
    "    print(\"mf.Q_ =\", mf.Q_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f7c68d1f16c634e85c1026734242b23",
     "grade": false,
     "grade_id": "cell-49173e4693137b25",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**DEBUG:** The previous cell should output:\n",
    "\n",
    "```\n",
    "model without baseline\n",
    "{'eta': 0.002, 'k': 5, 'lam': 0.0, 'n_epochs': 5, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1, 'w_average': False, 'w_biases': False}\n",
    "start of training\n",
    "epoch 0 loss 13.639409087626682\n",
    "epoch 1 loss 13.230478844754824\n",
    "epoch 2 loss 7.0618821126408635\n",
    "epoch 3 loss 2.725228011126733\n",
    "epoch 4 loss 1.7016379313310284\n",
    "\n",
    "after training:\n",
    "mf.P_ = [[-0.1698 -0.0308 -0.1026  0.3224 -0.5999]\n",
    " [-0.4869  0.194  -0.1285  0.365  -0.5793]\n",
    " [-0.2857 -0.16   -0.1121  0.4718 -0.7441]\n",
    " ...\n",
    " [-0.2098 -0.0308 -0.0361  0.3639 -0.7422]\n",
    " [-0.2596  0.1421 -0.0857  0.2301 -0.5589]\n",
    " [-0.2356  0.0529 -0.046   0.2977 -0.6761]]\n",
    "mf.Q_ = [[-1.5851  0.2133 -0.317   2.2759 -3.9413]\n",
    " [-1.1774  0.3314 -0.2151  1.7553 -3.2064]\n",
    " [-1.1776  0.1    -0.3964  1.6477 -3.046 ]\n",
    " ...\n",
    " [-0.0474 -0.0531 -0.1062  0.1721 -0.248 ]\n",
    " [-0.1908 -0.0122 -0.1645  0.3567 -0.5713]\n",
    " [-0.9779  0.0391  0.024   0.967  -2.0613]]\n",
    "\n",
    "model with baseline\n",
    "{'eta': 0.002, 'k': 5, 'lam': 0.0, 'n_epochs': 5, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1, 'w_average': True, 'w_biases': True}\n",
    "start of training\n",
    "epoch 0 loss 0.9467098876852351\n",
    "epoch 1 loss 0.8574775878207676\n",
    "epoch 2 loss 0.8225046228603675\n",
    "epoch 3 loss 0.800529367369865\n",
    "epoch 4 loss 0.7850515429727457\n",
    "\n",
    "after training:\n",
    "mf.P_ = [[ 0.1623 -0.0605 -0.0533 -0.1063  0.0838]\n",
    " [-0.2416  0.1707 -0.0822  0.0332 -0.0291]\n",
    " [ 0.1433 -0.2071 -0.0311 -0.042   0.1165]\n",
    " ...\n",
    " [ 0.0857 -0.0634 -0.0119 -0.0227 -0.0034]\n",
    " [-0.0315  0.1172 -0.0372 -0.063  -0.0469]\n",
    " [ 0.0272  0.0181  0.0175 -0.0461 -0.0552]]\n",
    "mf.Q_ = [[ 0.0207 -0.1148  0.0344 -0.0504  0.0295]\n",
    " [ 0.0193  0.1361  0.1138  0.1442 -0.0676]\n",
    " [ 0.0439 -0.07   -0.1378  0.034  -0.0398]\n",
    " ...\n",
    " [ 0.0567 -0.0603 -0.1154  0.0364 -0.0378]\n",
    " [ 0.0622  0.0091 -0.1184  0.0226  0.0074]\n",
    " [-0.1067 -0.0216  0.1438 -0.1057 -0.1115]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "736585c0f933ef1c46fbb334be03b348",
     "grade": true,
     "grade_id": "cell-2061485a463bd8e8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ebfa09aa2586cb0e4165aaddb01b5382",
     "grade": true,
     "grade_id": "vectorized-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6acaf2afed25162576cd6bd3fcff6f0a",
     "grade": false,
     "grade_id": "cell-113dd5d28baeab1c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Make Predictions --- TO EDIT\n",
    "\n",
    "The `predict` method takes as input a set of input user, item pairs in the form of an array `X` (not necessarily the same as that used for training), and returns the predicted ratings as an array `y_pred`.\n",
    "\n",
    "**TASK:** For each user, item pair in `X`:\n",
    "- predict a rating and store it into `y_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d2b047566b9bb713ab9b64af374abecc",
     "grade": false,
     "grade_id": "predict",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(self, X, y=None):\n",
    "    try:\n",
    "        getattr(self, \"n_users_\")\n",
    "    except AttributeError:\n",
    "        raise RuntimeError(\"You must train before predicting!\")\n",
    "    \n",
    "    \n",
    "    U, I = to_UI_arrays(X, self.n_users_, self.n_items_)\n",
    "    \n",
    "    y_pred = np.ndarray(U.shape[0])\n",
    "    \n",
    "    for index in range(U.shape[0]):\n",
    "        u = U[index]\n",
    "        i = I[index]\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        prediction = self.P_[u].T.dot(self.Q_[i])\n",
    "        if self.w_average:\n",
    "            prediction += self.mu_\n",
    "        if self.w_biases:\n",
    "            prediction += self.bu_[u] + self.bi_[i]\n",
    "        \n",
    "        y_pred[index] = prediction\n",
    "\n",
    "        \n",
    "    if y is not None:\n",
    "        mse = mean_squared_error(y_pred, y)\n",
    "        rmse = math.sqrt(mse)\n",
    "        print(\"RMSE\", rmse)\n",
    "        \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99931c4e9e99680c0514b1155d0a109c",
     "grade": false,
     "grade_id": "cell-8f98950e345bb2e2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Include it in the `MatrixFactorization` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bca1be1f3fe8e97e7f2eda018ca92b4f",
     "grade": false,
     "grade_id": "cell-814a6362fbec2ef7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "MatrixFactorization.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "50a5a42f8d9b88fb2bcbf3b6612403c8",
     "grade": false,
     "grade_id": "cell-347d2f72edcc10ee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 1.0597995576133503\n",
      "[3.5833 3.4484 3.6245 ... 3.3996 3.462  3.4427]\n"
     ]
    }
   ],
   "source": [
    "if DEBUG:\n",
    "    print(mf.predict(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf08e3449c1736096c548151881def5d",
     "grade": false,
     "grade_id": "cell-6ab07033bb048e49",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**DEBUG:** The previous cell should output:\n",
    "\n",
    "```\n",
    "RMSE 0.8809997299567512\n",
    "[3.2295 4.0322 3.8601 ... 3.4563 4.213  3.399 ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f121656a27b5b7fafd244f317cf476f",
     "grade": true,
     "grade_id": "predict-tests",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d326e9954b7c9cb3672bf0459681b157",
     "grade": false,
     "grade_id": "cell-8a8eca9b86015704",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Below are two functions used to evaluate the effectiveness of the recommender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "944044ce5c5c02e9bfff03eed93e5640",
     "grade": false,
     "grade_id": "cell-c9b627169ea360a3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def computeRMSE(self):\n",
    "    y_pred = self.predict(self.X_)\n",
    "    mse = mean_squared_error(y_pred, self.y_)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse, mse\n",
    "\n",
    "def score(self, X, y=None):\n",
    "    if y is None:\n",
    "        rmse, mse = self.computeRMSE()\n",
    "        return -rmse\n",
    "    else:\n",
    "        y_pred = self.predict(X)\n",
    "        mse = mean_squared_error(y_pred, y)\n",
    "        return -math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "04ee70a87c9b65050e4f3dd448ca6194",
     "grade": false,
     "grade_id": "cell-beafc96f3e175ccc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Also include them in the `MatrixFactorization` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "584c16b2034e72c7ae604b61aafd6942",
     "grade": false,
     "grade_id": "cell-0d59d8b2bff3e35c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "MatrixFactorization.computeRMSE = computeRMSE\n",
    "MatrixFactorization.score = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "88d58b046a33e30cd57d74829fd7bce5",
     "grade": false,
     "grade_id": "cell-aa9e0a305b48d5b5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Additional Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "MatrixFactorization.predict = predict\n",
    "MatrixFactorization.fit_init = fit_init\n",
    "MatrixFactorization.fit_sgd = fit_sgd\n",
    "MatrixFactorization.fit_mgd = fit_mgd\n",
    "MatrixFactorization.fit = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75ad158abb44110702d9ea4279a2dba8",
     "grade": false,
     "grade_id": "cell-39803d008b9eb70b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mf = MatrixFactorization()\n",
    "mf.k = 10\n",
    "mf.lam = 0.001\n",
    "mf.eta = 0.002\n",
    "mf.n_epochs = 10\n",
    "mf.s_batch = 1\n",
    "mf.w_average = True\n",
    "mf.w_biases = True\n",
    "\n",
    "%time mf.fit(X, y, n_users, n_items)\n",
    "\n",
    "y_pred = mf.predict(X,y)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f225f9dea30e087ba1aef3df8a00290",
     "grade": false,
     "grade_id": "cell-1f1429c87a137ed8",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**DEBUG**: The previous cell should output:\n",
    "```\n",
    "{'eta': 0.002, 'k': 10, 'lam': 0.001, 'n_epochs': 10, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1, 'w_average': True, 'w_biases': True}\n",
    "start of training\n",
    "epoch 0 loss 0.9507106291397593\n",
    "epoch 1 loss 0.8590495610491214\n",
    "epoch 2 loss 0.8232773658803088\n",
    "epoch 3 loss 0.8007329782739687\n",
    "epoch 4 loss 0.7847901829593874\n",
    "epoch 5 loss 0.7727912055338106\n",
    "epoch 6 loss 0.7633699654686578\n",
    "epoch 7 loss 0.7557260695103907\n",
    "epoch 8 loss 0.7493489153943951\n",
    "epoch 9 loss 0.743891555592705\n",
    "CPU times: user 1min 17s, sys: 790 ms, total: 1min 18s\n",
    "Wall time: 1min 19s\n",
    "RMSE 0.8594944026423732\n",
    "y_pred [3.1841 3.8918 3.8298 ... 3.5132 4.2292 3.4886]\n",
    "y [3.5 3.5 3.5 ... 3.5 4.  5. ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ea7a94b5a0e470c09c865f69493584c4",
     "grade": false,
     "grade_id": "cell-fc35b144aa6a0cfa",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mf = MatrixFactorization()\n",
    "mf.k = 10\n",
    "mf.lam = 0.001\n",
    "mf.eta = 0.002\n",
    "mf.n_epochs = 10\n",
    "mf.s_batch = 1\n",
    "mf.w_average = True\n",
    "mf.w_biases = False\n",
    "\n",
    "%time mf.fit(X, y, n_users, n_items)\n",
    "\n",
    "y_pred = mf.predict(X,y)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c62957813399b8668f543cf5878f62f3",
     "grade": false,
     "grade_id": "cell-7c7aa33b54022987",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**DEBUG**: The previous cell should output:\n",
    "```\n",
    "{'eta': 0.002, 'k': 10, 'lam': 0.001, 'n_epochs': 10, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1, 'w_average': True, 'w_biases': False}\n",
    "start of training\n",
    "epoch 0 loss 1.1209703847886336\n",
    "epoch 1 loss 1.120067412319799\n",
    "epoch 2 loss 1.119166258088919\n",
    "epoch 3 loss 1.1181743824848953\n",
    "epoch 4 loss 1.1169609077367804\n",
    "epoch 5 loss 1.115309437605747\n",
    "epoch 6 loss 1.112838802107659\n",
    "epoch 7 loss 1.1088688767474086\n",
    "epoch 8 loss 1.1022134865988296\n",
    "epoch 9 loss 1.090939129152342\n",
    "CPU times: user 1min 6s, sys: 704 ms, total: 1min 7s\n",
    "Wall time: 1min 7s\n",
    "RMSE 1.0402325452357721\n",
    "y_pred [3.5057 3.5041 3.6061 ... 3.5149 3.4733 3.5145]\n",
    "y [3.5 3.5 3.5 ... 3.5 4.  5. ]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "49afa451a86840fd92092f9d524f8358",
     "grade": false,
     "grade_id": "cell-8fbaa47b96ff2d18",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## BONUS POINT\n",
    "\n",
    "If you additionally implement the following method, you will be awarded a bonus point --- and you will also feel proud that you master vectorization!\n",
    "\n",
    "- Implement mini-batch stochastic gradient descent in a vectorized manner. You should implement method `fit_mgd` and include it in the class.\n",
    "\n",
    "\n",
    "The key is to use the `X` matrix. You may have to split it into a user matrix `X_U` and an item matrix `X_I` part. Then, use these matrices to repeat the appropriate rows from matrices `P` and `Q`. That is, you should create a matrix `PB` where its k-th row is the row of `P` corresponding to the user indicated at the k-th row of matrix `X_U`. Similarly you create a matrix `QB`. In the end, you should compute the inner product of each row of `PB` with the corresponding row of `QB`.\n",
    "\n",
    "\n",
    "Optionally, you may also implement `predict` in the similar vectorized manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "780a24ac2592db2dcd83c907aa8fbc69",
     "grade": false,
     "grade_id": "cell-7876618cd387bfae",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eta': 0.002, 'k': 10, 'lam': 0.001, 'n_epochs': 10, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1000, 'w_average': True, 'w_biases': False}\n",
      "start training\n",
      "9924 968\n",
      "X_ (394638, 10892)\n",
      "self.P_ (9924, 10)\n"
     ]
    }
   ],
   "source": [
    "mf = MatrixFactorization()\n",
    "mf.k = 10\n",
    "mf.lam = 0.001\n",
    "mf.eta = 0.002\n",
    "mf.n_epochs = 10\n",
    "mf.s_batch = 1000\n",
    "mf.w_average = True\n",
    "mf.w_biases = False\n",
    "\n",
    "%time mf.fit(X, y, n_users, n_items)\n",
    "\n",
    "y_pred = mf.predict(X,y)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2d31cc82f3716794e3a8e6e7f2a4882b",
     "grade": false,
     "grade_id": "cell-3094042b6a4ce7a0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Expected output:**\n",
    "Derived from truncated data ```DEBUG = True```\n",
    "```\n",
    "{'eta': 0.002, 'k': 10, 'lam': 0.001, 'n_epochs': 10, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1000, 'w_average': True, 'w_biases': False}\n",
    "start training\n",
    "9924 968\n",
    "X_ (394638, 10892)\n",
    "self.P_ (9924, 10)\n",
    "epoch 0 loss 1.1191333723537802\n",
    "epoch 1 loss 1.118227175637557\n",
    "epoch 2 loss 1.1173353788004845\n",
    "epoch 3 loss 1.1163666902740568\n",
    "epoch 4 loss 1.1151964757937785\n",
    "epoch 5 loss 1.1136231861155976\n",
    "epoch 6 loss 1.1112967899300752\n",
    "epoch 7 loss 1.1075985843538718\n",
    "epoch 8 loss 1.1014545613386342\n",
    "epoch 9 loss 1.0911077547189652\n",
    "CPU times: user 3.06 s, sys: 82.2 ms, total: 3.14 s\n",
    "Wall time: 3.18 s\n",
    "RMSE 1.041532740797242\n",
    "y_pred [3.5062 3.5048 3.6021 ... 3.5187 3.4791 3.5141]\n",
    "y [3.5 3.5 3.5 ... 3.5 4.  5. ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0690e13955c0f3335b3d56fa560a5192",
     "grade": false,
     "grade_id": "cell-6776dbfbe92781d2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mf = MatrixFactorization()\n",
    "mf.k = 10\n",
    "mf.lam = 0.001\n",
    "mf.eta = 0.002\n",
    "mf.n_epochs = 10\n",
    "mf.s_batch = 1000\n",
    "mf.w_average = True\n",
    "mf.w_biases = True\n",
    "\n",
    "%time mf.fit(X, y, n_users, n_items)\n",
    "\n",
    "y_pred = mf.predict(X,y)\n",
    "print(\"y_pred\", y_pred)\n",
    "print(\"y\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b8fbdd410d191a0f06b45e28f29ad848",
     "grade": false,
     "grade_id": "cell-236011bfab34b463",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Expected output:**\n",
    "```\n",
    "{'eta': 0.002, 'k': 10, 'lam': 0.001, 'n_epochs': 10, 'rnd_mean': 0, 'rnd_std': 0.1, 's_batch': 1000, 'w_average': True, 'w_biases': True}\n",
    "start training\n",
    "9924 968\n",
    "X_ (394638, 10892)\n",
    "self.P_ (9924, 10)\n",
    "epoch 0 loss 0.9494371432229923\n",
    "epoch 1 loss 0.8577499223785994\n",
    "epoch 2 loss 0.8220173488238905\n",
    "epoch 3 loss 0.7995001533886877\n",
    "epoch 4 loss 0.7835805700586336\n",
    "epoch 5 loss 0.77160479264564\n",
    "epoch 6 loss 0.7622090723884897\n",
    "epoch 7 loss 0.7545948294068388\n",
    "epoch 8 loss 0.7482532026351049\n",
    "epoch 9 loss 0.7428391454192339\n",
    "CPU times: user 3.5 s, sys: 70.4 ms, total: 3.57 s\n",
    "Wall time: 3.59 s\n",
    "RMSE 0.859641613813476\n",
    "y_pred [3.1803 3.8931 3.8339 ... 3.5298 4.2333 3.4882]\n",
    "y [3.5 3.5 3.5 ... 3.5 4.  5. ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to use this field for additional tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
